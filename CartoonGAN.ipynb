{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartoonGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/CartoonGAN/blob/main/CartoonGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMbzNjd_vMhL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXZ-VexSrDLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83457aad-bf73-48da-bb1e-f6436c9a24fe"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import os\r\n",
        "import json\r\n",
        "import re\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from PIL import Image, ImageFilter\r\n",
        "import sys\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tfa\r\n",
        "from tensorflow.python.client import device_lib\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "#!unzip /content/drive/My\\ Drive/NN/spirited_away.zip -d /content/drive/My\\ Drive/NN/\r\n",
        "#!ls /content/drive/My\\ Drive/NN/\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  print('GPU device not found')\r\n",
        "else:\r\n",
        "    print('Found GPU at: {}'.format(device_name))\r\n",
        "    print(device_lib.list_local_devices()[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found GPU at: /device:GPU:0\n",
            "name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15692777408\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 8833543177545176705\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdnuXj0RPVcA"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krWmM57TPCiQ"
      },
      "source": [
        "###Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzLDODzQO834"
      },
      "source": [
        "models_dir = \"/content/drive/My Drive/NN/\"\r\n",
        "\r\n",
        "def savemodel(model,problem):\r\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\r\n",
        "    model.save(filename)\r\n",
        "    print(\"\\nModel saved successfully on file %s\\n\" %filename)\r\n",
        "\r\n",
        "#savemodel(D,'discriminator_0')\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIfpasF6PGW7"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayYkEJH4PBTr"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "from keras.layers import *\r\n",
        "models_dir = \"/content/drive/My Drive/NN/\"\r\n",
        "model_name = \"initialization_phase_generator\"\r\n",
        "\r\n",
        "def loadmodel(problem):\r\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\r\n",
        "    try:\r\n",
        "        model = load_model(filename)\r\n",
        "        print(\"\\nModel loaded successfully from file %s\\n\" %filename)\r\n",
        "    except OSError:    \r\n",
        "        print(\"\\nModel file %s not found!!!\\n\" %filename)\r\n",
        "        model = None\r\n",
        "    return model\r\n",
        "\r\n",
        "#gen_pretrained = loadmodel(model_name)\r\n",
        "#gen_trained = loadmodel(\"generator_01\")\r\n",
        "#disc_trained = loadmodel(\"discriminator_01\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-YKrNy03kop"
      },
      "source": [
        "### Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP71uC9H3SLE"
      },
      "source": [
        "'''#load imgs ?\r\n",
        "data_dir = '/content/drive/My Drive/NN/photos_rszd'\r\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,   validation_split=0.2, horizontal_flip=True)\r\n",
        "\r\n",
        "train_gen = train_datagen.flow_from_directory(\r\n",
        "        data_dir,\r\n",
        "        subset=\"training\",\r\n",
        "        seed=123,\r\n",
        "        target_size=(256, 256),\r\n",
        "        batch_size=32\r\n",
        "        )\r\n",
        "validation_generator = train_datagen.flow_from_directory(\r\n",
        "        data_dir,\r\n",
        "        target_size=(256,256),\r\n",
        "        batch_size=32,\r\n",
        "        )\r\n",
        "'''\r\n",
        "from glob import glob\r\n",
        "def get_dataset(dataset_name, batch_size):\r\n",
        "    files = glob(os.path.join('/content/drive/My Drive/NN/', dataset_name, \"*\"))\r\n",
        "    num_images = len(files)\r\n",
        "    print(f\"Found {num_images}  images in {dataset_name} folder.\")\r\n",
        "    ds = tf.data.Dataset.from_tensor_slices(files)\r\n",
        "    ds = ds.shuffle(num_images)\r\n",
        "    ds = ds.repeat()\r\n",
        "\r\n",
        "    def fn(filename):\r\n",
        "        x = tf.io.read_file(filename)\r\n",
        "        x = tf.image.decode_jpeg(x, channels=3)\r\n",
        "        img = tf.cast(x, tf.float32) / 127.5 - 1\r\n",
        "        #print(\"\\n tipo img = \",type(img),\"\\n tipo x = \",type(x), filename, type(filename))\r\n",
        "        return img\r\n",
        "\r\n",
        "    ds = ds.map(fn, batch_size)\r\n",
        "    ds = ds.batch(batch_size)\r\n",
        "    \r\n",
        "    steps = int(np.ceil(num_images/batch_size))\r\n",
        "    # user iter(ds) to avoid generating iterator every epoch\r\n",
        "    return iter(ds), steps\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baJ4P2PZHEyK"
      },
      "source": [
        "# 1 - Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGA5HMGtdieJ"
      },
      "source": [
        "### 1.1 - Resizing images\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHyCYxUUOLPx"
      },
      "source": [
        "def resize(path):\r\n",
        "    for item in os.listdir(path):\r\n",
        "            im = Image.open(os.path.join(path,item))\r\n",
        "            f, e = os.path.splitext(item)\r\n",
        "            imResize = im.resize((256,256), Image.ANTIALIAS)\r\n",
        "            print(f)\r\n",
        "            imResize.save(path+\"_resized/\" + f + ' resized.jpg', 'JPEG', quality=90)\r\n",
        "\r\n",
        "#!unzip /content/drive/My\\ Drive/NN/photos_from_COCO.zip -d /content/drive/My\\ Drive/NN/\r\n",
        "resize('/content/drive/My Drive/NN/photos_from_COCO')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhGxFlNBd5S1"
      },
      "source": [
        "### 1.2 Apply canny, dilate edge and gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0c8rFFBcs8X"
      },
      "source": [
        "def edge_smoothing(cartoon_images_filename, smoothed_images_filename):\r\n",
        "    print(\"Edge-smoothing of \", cartoon_images_filename)\r\n",
        "    origin = cv2.imread(cartoon_images_filename)\r\n",
        "    edges = createEdgesOverlay(origin)\r\n",
        "    result = overlayEdges(edges, origin)\r\n",
        "    #show_images(origin, edges, result)\r\n",
        "    result.save(smoothed_images_filename, \"JPEG\")\r\n",
        "\r\n",
        "def overlayEdges(edges, origin):\r\n",
        "    background = transformFromCV2ToPillowImageFormat(origin)\r\n",
        "    background.paste(edges, (0, 0), edges)\r\n",
        "    background = background.convert(\"RGB\")\r\n",
        "    return background\r\n",
        "\r\n",
        "def transformFromCV2ToPillowImageFormat(img):\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGBA)\r\n",
        "    return Image.fromarray(img)\r\n",
        "\r\n",
        "def createEdgesOverlay(origin):\r\n",
        "    edges = cv2.Canny(origin, 30, 300, 3) \r\n",
        "    edges = cv2.dilate(edges, (3, 3))\r\n",
        "    edges = cv2.bitwise_not(edges)\r\n",
        "    edges = transformFromCV2ToPillowImageFormat(edges)\r\n",
        "    makeWhiteBackgroundTransparent(edges)\r\n",
        "    edges = edges.filter(ImageFilter.GaussianBlur) #do blurring here because doing it before making background transparent results in white halo\r\n",
        "\r\n",
        "    return edges\r\n",
        "\r\n",
        "def makeWhiteBackgroundTransparent(img):\r\n",
        "    datas = img.getdata()\r\n",
        "    newData = []\r\n",
        "    for item in datas:\r\n",
        "        if item[0] == 255 and item[1] == 255 and item[2] == 255:\r\n",
        "            newData.append((255, 255, 255, 0))\r\n",
        "        else:\r\n",
        "            newData.append(item)\r\n",
        "    img.putdata(newData)\r\n",
        "\r\n",
        "def show_images(img,edges,result):\r\n",
        "    plt.subplot(131),plt.imshow(img)\r\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\r\n",
        "\r\n",
        "    plt.subplot(132),plt.imshow(edges)\r\n",
        "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\r\n",
        "    \r\n",
        "    plt.subplot(133),plt.imshow(result)\r\n",
        "    plt.title('Result Image'), plt.xticks([]), plt.yticks([])\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "path_resized = \"/content/drive/My Drive/NN/spirited_away_resized/\"\r\n",
        "path_smoothed = \"/content/drive/My Drive/NN/spirited_away_resized_smoothed/\"\r\n",
        "\r\n",
        "\r\n",
        "for filename in os.listdir(path_resized):\r\n",
        "  #filename='scene43626 resized.jpg'\r\n",
        "  f = filename.split(\" \")[0] + \" smoothed\"\r\n",
        "  cartoon_images_filename = path_resized + filename\r\n",
        "  smoothed_images_filename = path_smoothed + f\r\n",
        "  edge_smoothing(cartoon_images_filename, smoothed_images_filename)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5co-q5KoHCGt"
      },
      "source": [
        "#2 - GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHaKZTnPsBn6"
      },
      "source": [
        "## Initialization Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNGVgxFP8b0"
      },
      "source": [
        "### Load VGG19 weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS1a5Ra-HD6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75e2095-b0f0-4895-db77-6d90178eac01"
      },
      "source": [
        "from keras import applications\r\n",
        "from keras.models import Model, Input\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import regularizers\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def transferNet(input_shape):\r\n",
        "    \r\n",
        "    # download model\r\n",
        "    base_model = applications.vgg19.VGG19(weights=\"imagenet\", include_top=False, input_shape=input_shape)\r\n",
        "    # get the output tensor from a layer of the feature extractor\r\n",
        "    tmp_vgg_output = base_model.get_layer(\"block4_conv3\").output\r\n",
        "    tmp_vgg_output = Conv2D(512, (3, 3), activation='linear', padding='same',name='block4_conv4')(tmp_vgg_output)\r\n",
        "    \r\n",
        "    vgg = Model(inputs=base_model.input, outputs=tmp_vgg_output)\r\n",
        "    vgg.load_weights(os.path.expanduser(os.path.join(\"~\", \".keras\", \"models\",\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")), by_name=True)\r\n",
        "\r\n",
        "    return vgg\r\n",
        "\r\n",
        "\r\n",
        "input_shape =(256,256,3)\r\n",
        "# load the pre-trained model\r\n",
        "vgg = transferNet(input_shape)\r\n",
        "vgg.summary()\r\n",
        "!ls ~/.keras/models\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "=================================================================\n",
            "Total params: 10,585,152\n",
            "Trainable params: 10,585,152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCcHgsTRbthT"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srtyDDuObvfV"
      },
      "source": [
        "from keras import applications\r\n",
        "from keras import layers\r\n",
        "from keras.models import Model, Input\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import *\r\n",
        "from keras import regularizers\r\n",
        "from keras import optimizers\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tfa\r\n",
        "\r\n",
        "\r\n",
        "def resblock(x_init):\r\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, padding='same')(x_init)\r\n",
        "    #x = (ZeroPadding2D(padding=(1, 1)))(x)\r\n",
        "    \r\n",
        "    x = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(x)\r\n",
        "    x = tf.nn.relu(x)\r\n",
        "    x = (Conv2D(256, kernel_size=3, strides=1, padding='same'))(x)\r\n",
        "    #x = (ZeroPadding2D(padding=(1, 1)))(x)\r\n",
        "    x = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(x)    \r\n",
        "\r\n",
        "    return x + x_init\r\n",
        "\r\n",
        "def create_generator(input_shape):\r\n",
        "    #model = Sequential()\r\n",
        "    #k7n64s1\r\n",
        "    input_t = tf.keras.layers.Input(shape=input_shape)\r\n",
        "    \r\n",
        "    model = (Conv2D(input_shape=input_shape, filters=64, kernel_size=7, strides=1, padding='same'))(input_t)\r\n",
        "    #model = (ZeroPadding2D(padding=(3, 3)))(model)\r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "    \r\n",
        "    #### Down-Convolution\r\n",
        "    \r\n",
        "    #k3 n128 s2\r\n",
        "    model = (Conv2D(filters=128, kernel_size=3, strides=2, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    #k3 n128 s1\r\n",
        "    model = (Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "\r\n",
        "\r\n",
        "    #k3 n256 s2\r\n",
        "    model = (Conv2D(filters=256, kernel_size=3, strides=2, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "\r\n",
        "    #k3 n256 s1\r\n",
        "    model = (Conv2D(filters=256, kernel_size=3, strides=1, padding='same', name=\"test\"))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    #TODO\r\n",
        "    # residual blocks\r\n",
        "    for i in range(8):#number of res blocks\r\n",
        "        '''model = (Conv2D(256, kernel_size=3, strides=1, padding='valid',activation=\"relu\"))(model)\r\n",
        "        model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "        \r\n",
        "        model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "        model = tf.nn.relu(model)\r\n",
        "\r\n",
        "        model = (Conv2D(256, kernel_size=3, strides=1, padding='valid',activation=\"relu\"))(model)\r\n",
        "        model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "        model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)'''\r\n",
        "        model = resblock(model)\r\n",
        "\r\n",
        "        \r\n",
        "        \r\n",
        "    \r\n",
        "    # Up-convolution\r\n",
        "    model = (Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',output_padding=1))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = (Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "    #######################\r\n",
        "    model = (Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same',output_padding=1))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = (Conv2D(filters=64, kernel_size=3, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "\r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "\r\n",
        "    ###\r\n",
        "    model = (Conv2D(filters=3, kernel_size=7, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(3, 3)))(model)\r\n",
        "    model = tf.tanh(model)\r\n",
        "\r\n",
        "    #model.compile(loss=tf.keras.losses.BinaryCrossentropy)\r\n",
        "    model = Model(inputs=input_t, outputs=model, name=\"generator\")\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "#G = create_generator(input_shape=(256,256,3))\r\n",
        "#G.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA6DDNnrdhex"
      },
      "source": [
        "\r\n",
        "#### Generator training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5qzOVIAyPO"
      },
      "source": [
        "#TODO\r\n",
        "from glob import glob\r\n",
        "import os\r\n",
        "from tqdm import tqdm\r\n",
        "import gc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def pretrain_step(vgg, input_images, generator, optimizer):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        generated_images = generator(input_images)\r\n",
        "\r\n",
        "        plt.imshow(generated_images[0])\r\n",
        "        plt.imshow(input_images[0])\r\n",
        "        mae = tf.keras.losses.MeanAbsoluteError()\r\n",
        "        c_loss = mae(vgg(input_images), vgg(generated_images))\r\n",
        "\r\n",
        "        gradients = tape.gradient(c_loss, generator.trainable_variables)\r\n",
        "        optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\r\n",
        "        content_loss_metric = tf.keras.metrics.Mean(\"content_loss\", dtype=tf.float32)\r\n",
        "        content_loss_metric(c_loss)\r\n",
        "\r\n",
        "def pretrain_generator(dataset_name,batch_size):\r\n",
        "    summary_writer = tf.summary.create_file_writer(os.path.join('/content/drive/My Drive/NN', \"pretrain\"))\r\n",
        "    print(f\"Starting to pretrain generator with 10 epochs...\")\r\n",
        "    print(f\"Building `{dataset_name}` dataset\")\r\n",
        "    dataset, steps_per_epoch = get_dataset(dataset_name=dataset_name, batch_size=batch_size)\r\n",
        "    \r\n",
        "    generator = G\r\n",
        "    #generator(tf.keras.Input(shape=(None,256,256, 3)))\r\n",
        "    #generator.summary()\r\n",
        "\r\n",
        "    print(\"Setting up optimizer to update generator's parameters...\")\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0008, beta_1=0.5)\r\n",
        "\r\n",
        "    trained_epochs = 0\r\n",
        "    epochs = 10\r\n",
        "\r\n",
        "    print(\"Proceeding pretraining without sample images...\")\r\n",
        "\r\n",
        "    print(\"Starting pre-training loop, setting up summary writer to record progress on TensorBoard...\")\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        epoch_idx = trained_epochs + epoch + 1\r\n",
        "\r\n",
        "        for step in tqdm(range(1, steps_per_epoch + 1), desc=f\"Pretrain Epoch {epoch + 1}/{epochs}\"):\r\n",
        "            image_batch = dataset.next()\r\n",
        "            pretrain_step(vgg, image_batch, generator, optimizer)\r\n",
        "\r\n",
        "            if step % 100 == 0: #100 = pretrain_reporting_steps\r\n",
        "                global_step = (epoch_idx - 1) * steps_per_epoch + step\r\n",
        "                with summary_writer.as_default():\r\n",
        "                    tf.summary.scalar('content_loss', tf.keras.metrics.Mean(\"content_loss\", dtype=tf.float32).result(), step=global_step)\r\n",
        "\r\n",
        "                tf.keras.metrics.Mean(\"content_loss\", dtype=tf.float32).reset_states()\r\n",
        "        gc.collect()\r\n",
        "    return generator\r\n",
        "        \r\n",
        "#gen_pretrained = pretrain_generator(\"photos_rszd/photos_resized\", 16)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUPngw40dkbA"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StFKZT3Xdj6J"
      },
      "source": [
        "def create_discriminator(input_shape):\r\n",
        "    model = Sequential()\r\n",
        "    #k7n64s1\r\n",
        "    model.add(Conv2D(input_shape=input_shape, filters=32, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(LeakyReLU())\r\n",
        "\r\n",
        "    #k3n64s2\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=3, strides=2, padding='same'))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "    \r\n",
        "    #k3n128s1\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(tfa.layers.InstanceNormalization(axis=3, center=True, scale=True))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    \r\n",
        "    #k3n128s2\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=2, padding='same'))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "    #k3n256s1\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(tfa.layers.InstanceNormalization(axis=3, center=True, scale=True))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    #k3n256s1\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(tfa.layers.InstanceNormalization(axis=3, center=True, scale=True))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    #k3n1s1\r\n",
        "    model.add(Conv2D(filters=1, kernel_size=3, strides=1, padding='same'))\r\n",
        "   \r\n",
        "    \r\n",
        "    #model.compile(loss=tf.keras.losses.BinaryCrossentropy)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "#D = create_discriminator(input_shape=(256,256,3))\r\n",
        "#D.summary()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwtFZGzY3ijx"
      },
      "source": [
        "## Adversarial model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnvicjC5wMzi"
      },
      "source": [
        "#### Get datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L35BLKrqwQAW",
        "outputId": "2c93a0c3-accd-4c8f-890d-3908d6a050c3"
      },
      "source": [
        "from itertools import product\r\n",
        "from imageio import imwrite,imread\r\n",
        "import gc\r\n",
        "from IPython.display import Image,display\r\n",
        "\r\n",
        "\r\n",
        "cartoon_set,steps_per_epoch = get_dataset(\"paprika_resized\",8)\r\n",
        "cartoon_smoothed_set, steps_per_epoch = get_dataset(\"paprika_resized_smoothed\",8)\r\n",
        "normal_photos_set,steps_per_epoch_normal = get_dataset(\"photos_rszd/photos_resized\",8)\r\n",
        "\r\n",
        "#New dataset name = photos_from_COCO_resized\r\n",
        "dataset_COCO, steps_per_epoch_coco = get_dataset(dataset_name=\"photos_from_COCO_resized\", batch_size=16)\r\n",
        "seed = dataset_COCO.next()\r\n",
        "\r\n",
        "\r\n",
        "def _save_generated_images(batch_x, image_name, nrow=2, ncol=4):\r\n",
        "    if not isinstance(batch_x, np.ndarray):\r\n",
        "        batch_x = batch_x.numpy()\r\n",
        "    n, h, w, c = batch_x.shape\r\n",
        "    out_arr = np.zeros([h * nrow, w * ncol, 3], dtype=np.uint8)\r\n",
        "    for (i, j), k in zip(product(range(nrow), range(ncol)), range(n)):\r\n",
        "        out_arr[(h * i):(h * (i+1)), (w * j):(w * (j+1))] = batch_x[k]\r\n",
        "    path_name = os.path.join(\"/content/drive/My Drive/NN/training\", image_name)\r\n",
        "    imwrite(path_name, out_arr)\r\n",
        "    display(Image(path_name,width=256, height=256))\r\n",
        "    gc.collect()\r\n",
        "    return out_arr\r\n",
        "\r\n",
        "#_save_generated_images(tf.cast((gen_pretrained(seed, training=False) + 1) * 127.5, tf.uint8),\"test.png\" )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3591  images in paprika_resized folder.\n",
            "Found 3592  images in paprika_resized_smoothed folder.\n",
            "Found 3747  images in photos_rszd/photos_resized folder.\n",
            "Found 2217  images in photos_from_COCO_resized folder.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn5dJVoCwDZj"
      },
      "source": [
        "#### Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANRjg4TiuXKA"
      },
      "source": [
        "generator_optimizer = keras.optimizers.Adam(1e-4)\r\n",
        "discriminator_optimizer = keras.optimizers.Adam(1e-4)\r\n",
        "\r\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\r\n",
        "discr_loss_bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "\r\n",
        "def discriminator_loss (real, fake, real_blur):\r\n",
        "    real_loss = discr_loss_bce(tf.ones_like(real), real)\r\n",
        "    fake_loss = discr_loss_bce(tf.zeros_like(fake), fake)\r\n",
        "    real_blur_loss = discr_loss_bce(tf.zeros_like(real_blur), real_blur)\r\n",
        "    #insert metrics\r\n",
        "    d_real_loss_metric(real_loss)\r\n",
        "    d_fake_loss_metric(fake_loss)\r\n",
        "    d_smooth_loss_metric(real_blur_loss)\r\n",
        "    return real_loss+fake_loss+real_blur_loss\r\n",
        "\r\n",
        "def generator_loss(fake):\r\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(fake), logits=fake))\r\n",
        "\r\n",
        "\r\n",
        "g_total_loss_metric = tf.keras.metrics.Mean(\"g_total_loss\", dtype=tf.float32)\r\n",
        "g_adv_loss_metric = tf.keras.metrics.Mean(\"g_adversarial_loss\", dtype=tf.float32)\r\n",
        "content_loss_metric = tf.keras.metrics.Mean(\"content_loss\", dtype=tf.float32)\r\n",
        "style_loss_metric = tf.keras.metrics.Mean(\"style_loss\", dtype=tf.float32)\r\n",
        "d_total_loss_metric = tf.keras.metrics.Mean(\"d_total_loss\", dtype=tf.float32)\r\n",
        "d_real_loss_metric = tf.keras.metrics.Mean(\"d_real_loss\", dtype=tf.float32)\r\n",
        "d_fake_loss_metric = tf.keras.metrics.Mean(\"d_fake_loss\", dtype=tf.float32)\r\n",
        "d_smooth_loss_metric = tf.keras.metrics.Mean(\"d_smooth_loss\", dtype=tf.float32)\r\n",
        "metric_and_names = [\r\n",
        "    (g_total_loss_metric, \"g_total_loss\"),\r\n",
        "    (g_adv_loss_metric, \"g_adversarial_loss\"),\r\n",
        "    (d_total_loss_metric, \"d_total_loss\"),\r\n",
        "    (d_real_loss_metric, \"d_real_loss\"),\r\n",
        "    (d_fake_loss_metric, \"d_fake_loss\"),\r\n",
        "    (d_smooth_loss_metric, \"d_smooth_loss\"),\r\n",
        "    (content_loss_metric, \"content_loss\")\r\n",
        "]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4y0r_NF-Uw1"
      },
      "source": [
        "### Training GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frlQ1ENy6Ufu"
      },
      "source": [
        "import time\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "%load_ext tensorboard\r\n",
        "import datetime, os\r\n",
        "\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def train_step(cartoon_set_batch, cartoon_smoothed_batch, normal_photos_batch, generator, discriminator):\r\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n",
        "        generated_images = generator(normal_photos_batch, training=True)\r\n",
        "\r\n",
        "        real_output = discriminator(cartoon_set_batch, training=True)\r\n",
        "        fake_output = discriminator(generated_images, training=True)\r\n",
        "        real_smooth_output = discriminator(cartoon_smoothed_batch, training=True)\r\n",
        "        \r\n",
        "        disc_loss = discriminator_loss(real_output, fake_output, real_smooth_output)\r\n",
        "        \r\n",
        "        gen_adv_loss = generator_loss(fake_output)\r\n",
        "        c_loss = mae(vgg(normal_photos_batch), vgg(generated_images))\r\n",
        "        gen_total_loss = gen_adv_loss + c_loss\r\n",
        "        \r\n",
        "        \r\n",
        "\r\n",
        "    gradients_of_generator = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\r\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\r\n",
        "\r\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\r\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\r\n",
        "\r\n",
        "    g_total_loss_metric(gen_total_loss)\r\n",
        "    content_loss_metric(c_loss)\r\n",
        "    d_total_loss_metric(disc_loss)\r\n",
        "\r\n",
        "    return disc_loss, gen_total_loss, c_loss \r\n",
        "\r\n",
        "def train(cartoon_set, cartoon_smoothed_set, normal_photos_set, epochs,prec_epochs, gen_pretrained, D):\r\n",
        "    summary_writer = tf.summary.create_file_writer(\"/content/drive/My Drive/NN/training/logs\")\r\n",
        "    with summary_writer.as_default():\r\n",
        "        img = np.expand_dims(_save_generated_images(\r\n",
        "            tf.cast((normal_photos_set.next() + 1) * 127.5, tf.uint8),image_name=\"gan_sample_images.png\"), 0,)\r\n",
        "        tf.summary.image(\"gan_sample_images\", img, step=0)\r\n",
        "        img = np.expand_dims(_save_generated_images(tf.cast((cartoon_set.next() + 1) * 127.5, tf.uint8),\r\n",
        "            image_name=\"gan_val_sample_images.png\"), 0,)\r\n",
        "        tf.summary.image(\"gan_val_sample_images\", img, step=0)\r\n",
        "\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        start = time.time()\r\n",
        "        for step in tqdm(\r\n",
        "                    range(1, steps_per_epoch + 1),\r\n",
        "                    desc=f'Train {epoch + 1+prec_epochs}/{epochs+prec_epochs}',\r\n",
        "                    total=steps_per_epoch):\r\n",
        "            cart_batch = cartoon_set.next()\r\n",
        "            cart_smooth_batch = cartoon_smoothed_set.next()\r\n",
        "            norm_photos_batch = normal_photos_set.next()\r\n",
        "\r\n",
        "            d_loss,g_loss,c_loss = train_step(cart_batch, cart_smooth_batch, norm_photos_batch,gen_pretrained,D)\r\n",
        "\r\n",
        "        with summary_writer.as_default():\r\n",
        "            for metric, name in metric_and_names:\r\n",
        "                tf.summary.scalar(name, metric.result(), step=epoch+prec_epochs+1)\r\n",
        "                metric.reset_states()    \r\n",
        "            \r\n",
        "            fake_batch = tf.cast(\r\n",
        "                (gen_pretrained(norm_photos_batch, training=False) + 1) * 127.5, tf.uint8)\r\n",
        "            img = np.expand_dims(_save_generated_images(\r\n",
        "                    fake_batch,\r\n",
        "                    image_name=(\"gan_val_generated_images_at_epoch_\"f\"{epoch+1+prec_epochs}.png\")\r\n",
        "                    ),0,\r\n",
        "                )\r\n",
        "            _save_generated_images(norm_photos_batch, image_name=(\"val_images_at_epoch_\"f\"{epoch+1+prec_epochs}.png\"))\r\n",
        "            tf.summary.image('gan_val_generated_images', img, step=epoch+1+prec_epochs)\r\n",
        "\r\n",
        "        print(\"Epoch:  [%5d/%5d] time: %4.4f content_loss: %.8f\" % (epoch+1, epochs+prec_epochs, time.time() - start, c_loss))\r\n",
        "        print(\"Epoch:  [%5d/%5d] time: %4.4f disc_loss: %.8f, gen_loss: %.8f\" % (epoch+1, epochs+prec_epochs, time.time() - start, d_loss, g_loss))\r\n",
        "\r\n",
        "    # Generate after the final epoch\r\n",
        "    return gen_pretrained, D\r\n",
        "\r\n",
        "\r\n",
        "gen_pretrained = loadmodel(\"generator_new_20+10e\")\r\n",
        "D = loadmodel(\"discriminator_new_20+10e\")\r\n",
        "#D = create_discriminator(input_shape=(256,256,3))\r\n",
        "\r\n",
        "#%tensorboard --logdir \"/content/drive/My Drive/NN/training/logs\"\r\n",
        "generator_trained, discriminator_trained = train(cartoon_set, cartoon_smoothed_set, dataset_COCO, 40,30, gen_pretrained, D)\r\n",
        "\r\n",
        "savemodel(discriminator_trained,'discriminator_new_70e')\r\n",
        "savemodel(generator_trained,'generator_new_70e')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs1VgHHjq41b"
      },
      "source": [
        "generator_trained.save_weights(os.path.join(models_dir, \"generator\"))\r\n",
        "%tensorboard --logdir \"/content/drive/My Drive/NN/training/logs\"\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}