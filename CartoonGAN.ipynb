{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartoonGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/CartoonGAN/blob/main/CartoonGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMbzNjd_vMhL"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXZ-VexSrDLg"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import os\r\n",
        "import json\r\n",
        "import re\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from PIL import Image, ImageFilter\r\n",
        "import sys\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import tensorflow as tf\r\n",
        "drive.mount('/content/drive')\r\n",
        "#!unzip /content/drive/My\\ Drive/NN/spirited_away.zip -d /content/drive/My\\ Drive/NN/\r\n",
        "#!ls /content/drive/My\\ Drive/NN/\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdnuXj0RPVcA"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krWmM57TPCiQ"
      },
      "source": [
        "###Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzLDODzQO834"
      },
      "source": [
        "models_dir = \"/content/drive/My Drive/NN/\"\r\n",
        "\r\n",
        "def savemodel(model,problem):\r\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\r\n",
        "    model.save(filename)\r\n",
        "    print(\"\\nModel saved successfully on file %s\\n\" %filename)\r\n",
        "\r\n",
        "# Save the model MWI-Dataset-1.1_models\r\n",
        "savemodel(model,'Twd_model_31_epochs_2000_images')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIfpasF6PGW7"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayYkEJH4PBTr"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "\r\n",
        "models_dir = \"/content/drive/My Drive/NN/\"\r\n",
        "model_name = \"towards_model_100_epochs_2000_images_acc44_256\"\r\n",
        "\r\n",
        "def loadmodel(problem):\r\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\r\n",
        "    try:\r\n",
        "        model = load_model(filename)\r\n",
        "        print(\"\\nModel loaded successfully from file %s\\n\" %filename)\r\n",
        "    except OSError:    \r\n",
        "        print(\"\\nModel file %s not found!!!\\n\" %filename)\r\n",
        "        model = None\r\n",
        "    return model\r\n",
        "\r\n",
        "model = loadmodel(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baJ4P2PZHEyK"
      },
      "source": [
        "# 1 - Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGA5HMGtdieJ"
      },
      "source": [
        "### 1.1 - Resizing images\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHyCYxUUOLPx"
      },
      "source": [
        "def resize(path):\r\n",
        "    for item in os.listdir(path):\r\n",
        "            im = Image.open(path+item)\r\n",
        "            f, e = os.path.splitext(item)\r\n",
        "            imResize = im.resize((256,256), Image.ANTIALIAS)\r\n",
        "            print(f)\r\n",
        "            imResize.save(path+\"_resized/\" + f + ' resized.jpg', 'JPEG', quality=90)\r\n",
        "\r\n",
        "resize('/content/drive/My Drive/NN/your_name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhGxFlNBd5S1"
      },
      "source": [
        "### 1.2 Apply canny, dilate edge and gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0c8rFFBcs8X"
      },
      "source": [
        "def edge_smoothing(cartoon_images_filename, smoothed_images_filename):\r\n",
        "    print(\"Edge-smoothing of \", cartoon_images_filename)\r\n",
        "    origin = cv2.imread(cartoon_images_filename)\r\n",
        "    edges = createEdgesOverlay(origin)\r\n",
        "    result = overlayEdges(edges, origin)\r\n",
        "    #show_images(origin, edges, result)\r\n",
        "    result.save(smoothed_images_filename, \"JPEG\")\r\n",
        "\r\n",
        "def overlayEdges(edges, origin):\r\n",
        "    background = transformFromCV2ToPillowImageFormat(origin)\r\n",
        "    background.paste(edges, (0, 0), edges)\r\n",
        "    background = background.convert(\"RGB\")\r\n",
        "    return background\r\n",
        "\r\n",
        "def transformFromCV2ToPillowImageFormat(img):\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGBA)\r\n",
        "    return Image.fromarray(img)\r\n",
        "\r\n",
        "def createEdgesOverlay(origin):\r\n",
        "    edges = cv2.Canny(origin, 30, 300, 3) \r\n",
        "    edges = cv2.dilate(edges, (3, 3))\r\n",
        "    edges = cv2.bitwise_not(edges)\r\n",
        "    edges = transformFromCV2ToPillowImageFormat(edges)\r\n",
        "    makeWhiteBackgroundTransparent(edges)\r\n",
        "    edges = edges.filter(ImageFilter.GaussianBlur) #do blurring here because doing it before making background transparent results in white halo\r\n",
        "\r\n",
        "    return edges\r\n",
        "\r\n",
        "def makeWhiteBackgroundTransparent(img):\r\n",
        "    datas = img.getdata()\r\n",
        "    newData = []\r\n",
        "    for item in datas:\r\n",
        "        if item[0] == 255 and item[1] == 255 and item[2] == 255:\r\n",
        "            newData.append((255, 255, 255, 0))\r\n",
        "        else:\r\n",
        "            newData.append(item)\r\n",
        "    img.putdata(newData)\r\n",
        "\r\n",
        "def show_images(img,edges,result):\r\n",
        "    plt.subplot(131),plt.imshow(img)\r\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\r\n",
        "\r\n",
        "    plt.subplot(132),plt.imshow(edges)\r\n",
        "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\r\n",
        "    \r\n",
        "    plt.subplot(133),plt.imshow(result)\r\n",
        "    plt.title('Result Image'), plt.xticks([]), plt.yticks([])\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "path_resized = \"/content/drive/My Drive/NN/spirited_away_resized/\"\r\n",
        "path_smoothed = \"/content/drive/My Drive/NN/spirited_away_resized_smoothed/\"\r\n",
        "\r\n",
        "\r\n",
        "for filename in os.listdir(path_resized):\r\n",
        "  #filename='scene43626 resized.jpg'\r\n",
        "  f = filename.split(\" \")[0] + \" smoothed\"\r\n",
        "  cartoon_images_filename = path_resized + filename\r\n",
        "  smoothed_images_filename = path_smoothed + f\r\n",
        "  edge_smoothing(cartoon_images_filename, smoothed_images_filename)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5co-q5KoHCGt"
      },
      "source": [
        "#2 - GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-YKrNy03kop"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP71uC9H3SLE",
        "outputId": "4e9699ee-5499-4be9-c189-2e9014776445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#load imgs ?\r\n",
        "data_dir = '/content/drive/My Drive/NN/photos_rszd'\r\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,   validation_split=0.2, horizontal_flip=True)\r\n",
        "\r\n",
        "train_gen = train_datagen.flow_from_directory(\r\n",
        "        data_dir,\r\n",
        "        subset=\"training\",\r\n",
        "        seed=123,\r\n",
        "        target_size=(256, 256),\r\n",
        "        batch_size=32\r\n",
        "        )\r\n",
        "validation_generator = train_datagen.flow_from_directory(\r\n",
        "        data_dir,\r\n",
        "        target_size=(256,256),\r\n",
        "        batch_size=32,\r\n",
        "        )\r\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2998 images belonging to 1 classes.\n",
            "Found 3747 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNGVgxFP8b0"
      },
      "source": [
        "## Load VGG19 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS1a5Ra-HD6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd94e7a-276e-46ea-ada5-dfe2a3bd2e69"
      },
      "source": [
        "from keras import applications\r\n",
        "from keras.models import Model, Input\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import regularizers\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def transferNet(output_layer_name, input_shape):\r\n",
        "    \r\n",
        "    # download model\r\n",
        "    base_model = applications.vgg19.VGG19(weights=\"imagenet\", include_top=False, input_shape=input_shape)\r\n",
        "    # get the output tensor from a layer of the feature extractor\r\n",
        "    tmp_vgg_output = base_model.get_layer(\"block4_conv3\").output\r\n",
        "    tmp_vgg_output = Conv2D(512, (3, 3), activation='linear', padding='same',name='block4_conv4')(tmp_vgg_output)\r\n",
        "    \r\n",
        "    vgg = Model(inputs=base_model.input, outputs=tmp_vgg_output)\r\n",
        "    vgg.load_weights(os.path.expanduser(os.path.join(\"~\", \".keras\", \"models\",\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")), by_name=True)\r\n",
        "\r\n",
        "    return vgg\r\n",
        "\r\n",
        "\r\n",
        "input_shape =(256,256,3)\r\n",
        "# load the pre-trained model\r\n",
        "\r\n",
        "# choose the layer from which you can get the features \r\n",
        "name_output_extractor = \"block4_conv4\" #ultimo 3?\r\n",
        "\r\n",
        "# build the transfer model\r\n",
        "transfer_model = transferNet(name_output_extractor, input_shape)\r\n",
        "transfer_model.summary()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "=================================================================\n",
            "Total params: 10,585,152\n",
            "Trainable params: 10,585,152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCcHgsTRbthT"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srtyDDuObvfV",
        "outputId": "45dd211a-3555-43fe-8651-2f9103d5a3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras import applications\r\n",
        "from keras import layers\r\n",
        "from keras.models import Model, Input\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import *\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import regularizers\r\n",
        "from keras import optimizers\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "def generator():\r\n",
        "    model = Sequential()\r\n",
        "\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=7, strides=1, padding='valid',activation=\"relu\"))\r\n",
        "    model.add(ZeroPadding2D(padding=(3, 3)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    \r\n",
        "    #### Down-Convolution\r\n",
        "    \r\n",
        "    #k3 n128 s2\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=2, padding='valid',activation=\"relu\"))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    #k3 n128 s1\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='valid',activation=\"relu\"))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    #k3 n256 s2\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=2, padding='valid',activation=\"relu\"))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    #k3 n256 s1\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='valid',activation=\"relu\", name=\"test\"))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    \r\n",
        "    # residual blocks\r\n",
        "    for i in range(8):#number of res blocks\r\n",
        "        model.add(Conv2D(256, kernel_size=3, strides=1, padding='valid',activation=\"relu\"))\r\n",
        "        model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "        model.add(Conv2D(256, kernel_size=3, strides=1, padding='valid',activation=\"relu\"))\r\n",
        "        model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        model.add(BatchNormalization())\r\n",
        "        \r\n",
        "    \r\n",
        "    # Up-convolution\r\n",
        "    model.add(Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='valid',output_padding=1,activation='relu'))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    \r\n",
        "    model.add(Conv2DTranspose(filters=128, kernel_size=3, strides=1, padding='valid',activation='relu'))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    \r\n",
        "    model.add(BatchNormalization())\r\n",
        "    #######################\r\n",
        "    model.add(Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='valid',output_padding=1,activation='relu'))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    \r\n",
        "    model.add(Conv2DTranspose(filters=64, kernel_size=3, strides=1, padding='valid',activation='relu'))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    ###\r\n",
        "    model.add(Conv2D(filters=3, kernel_size=7, strides=1, padding='valid',activation=\"sigmoid\"))\r\n",
        "    model.add(ZeroPadding2D(padding=(3, 3)))\r\n",
        "\r\n",
        "\r\n",
        "    #model.compile(loss=tf.keras.losses.BinaryCrossentropy)\r\n",
        "    return model\r\n",
        "\r\n",
        "G = generator()\r\n",
        "G.build(input_shape=(None,256,256,3)) #todo\r\n",
        "G.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_105 (Conv2D)          (None, 250, 250, 64)      9472      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_125 (ZeroPadd (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_101 (Bat (None, 256, 256, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 127, 127, 128)     73856     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_126 (ZeroPadd (None, 129, 129, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_102 (Bat (None, 129, 129, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 127, 127, 128)     147584    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_127 (ZeroPadd (None, 129, 129, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_103 (Bat (None, 129, 129, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_128 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_104 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "test (Conv2D)                (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_129 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_105 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_130 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_131 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_106 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_107 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_132 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_133 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_108 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_109 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_134 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_135 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_110 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_111 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_136 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_137 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_112 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_113 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_138 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_139 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_114 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_115 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_140 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_141 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_116 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_117 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_121 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_142 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_122 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_143 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_118 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_119 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_123 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_144 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_124 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_145 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_120 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_121 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_16 (Conv2DT (None, 134, 134, 128)     295040    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_146 (ZeroPadd (None, 136, 136, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DT (None, 138, 138, 128)     147584    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_147 (ZeroPadd (None, 140, 140, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_122 (Bat (None, 140, 140, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_18 (Conv2DT (None, 282, 282, 64)      73792     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_148 (ZeroPadd (None, 284, 284, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_19 (Conv2DT (None, 286, 286, 64)      36928     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_149 (ZeroPadd (None, 288, 288, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_123 (Bat (None, 288, 288, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 282, 282, 3)       9411      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_150 (ZeroPadd (None, 288, 288, 3)       0         \n",
            "=================================================================\n",
            "Total params: 11,140,675\n",
            "Trainable params: 11,130,435\n",
            "Non-trainable params: 10,240\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUPngw40dkbA"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StFKZT3Xdj6J",
        "outputId": "5753e524-307b-47e2-efe7-1d9045da34cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def discriminator():\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='valid',activation=LeakyReLU()))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=3, strides=2, padding='valid',activation=LeakyReLU(alpha=0.2)))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='valid',activation=LeakyReLU(alpha=0.2)))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=2, padding='valid',activation=LeakyReLU(alpha=0.2)))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='valid',activation=LeakyReLU(alpha=0.2)))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "        \r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='valid',activation=LeakyReLU(alpha=0.2)))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "\r\n",
        "    model.add(Conv2D(filters=1, kernel_size=3, strides=1, padding='valid',activation=\"sigmoid\"))\r\n",
        "    model.add(ZeroPadding2D(padding=(1, 1)))\r\n",
        "    \r\n",
        "    #model.compile(loss=tf.keras.losses.BinaryCrossentropy)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "D = discriminator()\r\n",
        "D.build(input_shape=(None,256,256,3)) #todo\r\n",
        "D.summary()  "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_126 (Conv2D)          (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "zero_padding2d_151 (ZeroPadd (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_127 (Conv2D)          (None, 127, 127, 64)      18496     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_152 (ZeroPadd (None, 129, 129, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_128 (Conv2D)          (None, 127, 127, 128)     73856     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_153 (ZeroPadd (None, 129, 129, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_124 (Bat (None, 129, 129, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_129 (Conv2D)          (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_154 (ZeroPadd (None, 66, 66, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_130 (Conv2D)          (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_155 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_125 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_156 (ZeroPadd (None, 66, 66, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_126 (Bat (None, 66, 66, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_132 (Conv2D)          (None, 64, 64, 1)         2305      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_157 (ZeroPadd (None, 66, 66, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,130,945\n",
            "Trainable params: 1,129,665\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwtFZGzY3ijx"
      },
      "source": [
        "## Adversarial model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHNsMV7PjXPq"
      },
      "source": [
        "def create_GAN():\r\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\r\n",
        "\r\n",
        "    discriminator_model = Sequential()\r\n",
        "    discriminator_model.add(D)\r\n",
        "    discriminator_model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\r\n",
        "    adv_model = Sequential()\r\n",
        "    adv_model.add(G)\r\n",
        "    adv_model.add(D)\r\n",
        "    adv_model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    return adv_model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bhx1RgENNES"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLtWRfFSNBmY",
        "outputId": "48a438ec-add9-44c0-e636-c87d481e3cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "adv_model = create_GAN()\r\n",
        "adv_model.fit(\r\n",
        "        train_gen,\r\n",
        "        steps_per_epoch=2000,\r\n",
        "        epochs=50,\r\n",
        "        validation_data=validation_generator,\r\n",
        "        validation_steps=800,\r\n",
        "        verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA6DDNnrdhex"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5qzOVIAyPO"
      },
      "source": [
        "#TODO\r\n",
        "def my_loss_fn(y_true, y_pred):\r\n",
        "    squared_difference = tf.square(y_true - y_pred)\r\n",
        "    return tf.reduce_mean(squared_difference, axis=-1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}