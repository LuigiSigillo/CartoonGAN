{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartoonGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/CartoonGAN/blob/main/CartoonGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMbzNjd_vMhL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXZ-VexSrDLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04660fb-b132-47c6-a369-76f8973d9519"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import os\r\n",
        "import json\r\n",
        "import re\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from PIL import Image, ImageFilter\r\n",
        "import sys\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tfa\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "#!unzip /content/drive/My\\ Drive/NN/spirited_away.zip -d /content/drive/My\\ Drive/NN/\r\n",
        "#!ls /content/drive/My\\ Drive/NN/\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  print('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdnuXj0RPVcA"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krWmM57TPCiQ"
      },
      "source": [
        "###Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzLDODzQO834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f995660-02b0-496d-8010-4c388db108fe"
      },
      "source": [
        "models_dir = \"/content/drive/My Drive/NN/\"\r\n",
        "\r\n",
        "def savemodel(model,problem):\r\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\r\n",
        "    model.save(filename)\r\n",
        "    print(\"\\nModel saved successfully on file %s\\n\" %filename)\r\n",
        "\r\n",
        "# Save the model MWI-Dataset-1.1_models\r\n",
        "savemodel(D,'discriminator_01')\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model saved successfully on file /content/drive/My Drive/NN/discriminator_01.h5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIfpasF6PGW7"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayYkEJH4PBTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b993c9-9f96-41e0-d2f3-1fdc5e6695d1"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "\r\n",
        "models_dir = \"/content/drive/My Drive/NN/\"\r\n",
        "model_name = \"initialization_phase_generator\"\r\n",
        "\r\n",
        "def loadmodel(problem):\r\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\r\n",
        "    try:\r\n",
        "        model = load_model(filename)\r\n",
        "        print(\"\\nModel loaded successfully from file %s\\n\" %filename)\r\n",
        "    except OSError:    \r\n",
        "        print(\"\\nModel file %s not found!!!\\n\" %filename)\r\n",
        "        model = None\r\n",
        "    return model\r\n",
        "\r\n",
        "gen_pretrained = loadmodel(model_name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n",
            "WARNING:root:The given value for groups will be overwritten.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model loaded successfully from file /content/drive/My Drive/NN/initialization_phase_generator.h5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-YKrNy03kop"
      },
      "source": [
        "### Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP71uC9H3SLE"
      },
      "source": [
        "'''#load imgs ?\r\n",
        "data_dir = '/content/drive/My Drive/NN/photos_rszd'\r\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,   validation_split=0.2, horizontal_flip=True)\r\n",
        "\r\n",
        "train_gen = train_datagen.flow_from_directory(\r\n",
        "        data_dir,\r\n",
        "        subset=\"training\",\r\n",
        "        seed=123,\r\n",
        "        target_size=(256, 256),\r\n",
        "        batch_size=32\r\n",
        "        )\r\n",
        "validation_generator = train_datagen.flow_from_directory(\r\n",
        "        data_dir,\r\n",
        "        target_size=(256,256),\r\n",
        "        batch_size=32,\r\n",
        "        )\r\n",
        "'''\r\n",
        "from glob import glob\r\n",
        "def get_dataset(dataset_name, batch_size):\r\n",
        "    files = glob(os.path.join('/content/drive/My Drive/NN/', dataset_name, \"*\"))\r\n",
        "    num_images = len(files)\r\n",
        "    print(f\"Found {num_images}  images in {dataset_name} folder.\")\r\n",
        "    ds = tf.data.Dataset.from_tensor_slices(files)\r\n",
        "    ds = ds.shuffle(num_images)\r\n",
        "    ds = ds.repeat()\r\n",
        "\r\n",
        "    def fn(filename):\r\n",
        "        x = tf.io.read_file(filename)\r\n",
        "        x = tf.image.decode_jpeg(x, channels=3)\r\n",
        "        img = tf.cast(x, tf.float32) / 127.5 - 1\r\n",
        "        #print(\"\\n tipo img = \",type(img),\"\\n tipo x = \",type(x), filename, type(filename))\r\n",
        "        return img\r\n",
        "\r\n",
        "    ds = ds.map(fn, batch_size)\r\n",
        "    ds = ds.batch(batch_size)\r\n",
        "    \r\n",
        "    steps = int(np.ceil(num_images/batch_size))\r\n",
        "    # user iter(ds) to avoid generating iterator every epoch\r\n",
        "    return iter(ds), steps\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baJ4P2PZHEyK"
      },
      "source": [
        "# 1 - Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGA5HMGtdieJ"
      },
      "source": [
        "### 1.1 - Resizing images\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHyCYxUUOLPx"
      },
      "source": [
        "def resize(path):\r\n",
        "    for item in os.listdir(path):\r\n",
        "            im = Image.open(path+item)\r\n",
        "            f, e = os.path.splitext(item)\r\n",
        "            imResize = im.resize((256,256), Image.ANTIALIAS)\r\n",
        "            print(f)\r\n",
        "            imResize.save(path+\"_resized/\" + f + ' resized.jpg', 'JPEG', quality=90)\r\n",
        "\r\n",
        "resize('/content/drive/My Drive/NN/your_name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhGxFlNBd5S1"
      },
      "source": [
        "### 1.2 Apply canny, dilate edge and gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0c8rFFBcs8X"
      },
      "source": [
        "def edge_smoothing(cartoon_images_filename, smoothed_images_filename):\r\n",
        "    print(\"Edge-smoothing of \", cartoon_images_filename)\r\n",
        "    origin = cv2.imread(cartoon_images_filename)\r\n",
        "    edges = createEdgesOverlay(origin)\r\n",
        "    result = overlayEdges(edges, origin)\r\n",
        "    #show_images(origin, edges, result)\r\n",
        "    result.save(smoothed_images_filename, \"JPEG\")\r\n",
        "\r\n",
        "def overlayEdges(edges, origin):\r\n",
        "    background = transformFromCV2ToPillowImageFormat(origin)\r\n",
        "    background.paste(edges, (0, 0), edges)\r\n",
        "    background = background.convert(\"RGB\")\r\n",
        "    return background\r\n",
        "\r\n",
        "def transformFromCV2ToPillowImageFormat(img):\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGBA)\r\n",
        "    return Image.fromarray(img)\r\n",
        "\r\n",
        "def createEdgesOverlay(origin):\r\n",
        "    edges = cv2.Canny(origin, 30, 300, 3) \r\n",
        "    edges = cv2.dilate(edges, (3, 3))\r\n",
        "    edges = cv2.bitwise_not(edges)\r\n",
        "    edges = transformFromCV2ToPillowImageFormat(edges)\r\n",
        "    makeWhiteBackgroundTransparent(edges)\r\n",
        "    edges = edges.filter(ImageFilter.GaussianBlur) #do blurring here because doing it before making background transparent results in white halo\r\n",
        "\r\n",
        "    return edges\r\n",
        "\r\n",
        "def makeWhiteBackgroundTransparent(img):\r\n",
        "    datas = img.getdata()\r\n",
        "    newData = []\r\n",
        "    for item in datas:\r\n",
        "        if item[0] == 255 and item[1] == 255 and item[2] == 255:\r\n",
        "            newData.append((255, 255, 255, 0))\r\n",
        "        else:\r\n",
        "            newData.append(item)\r\n",
        "    img.putdata(newData)\r\n",
        "\r\n",
        "def show_images(img,edges,result):\r\n",
        "    plt.subplot(131),plt.imshow(img)\r\n",
        "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\r\n",
        "\r\n",
        "    plt.subplot(132),plt.imshow(edges)\r\n",
        "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\r\n",
        "    \r\n",
        "    plt.subplot(133),plt.imshow(result)\r\n",
        "    plt.title('Result Image'), plt.xticks([]), plt.yticks([])\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "path_resized = \"/content/drive/My Drive/NN/spirited_away_resized/\"\r\n",
        "path_smoothed = \"/content/drive/My Drive/NN/spirited_away_resized_smoothed/\"\r\n",
        "\r\n",
        "\r\n",
        "for filename in os.listdir(path_resized):\r\n",
        "  #filename='scene43626 resized.jpg'\r\n",
        "  f = filename.split(\" \")[0] + \" smoothed\"\r\n",
        "  cartoon_images_filename = path_resized + filename\r\n",
        "  smoothed_images_filename = path_smoothed + f\r\n",
        "  edge_smoothing(cartoon_images_filename, smoothed_images_filename)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5co-q5KoHCGt"
      },
      "source": [
        "#2 - GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHaKZTnPsBn6"
      },
      "source": [
        "## Initialization Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNGVgxFP8b0"
      },
      "source": [
        "### Load VGG19 weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS1a5Ra-HD6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6080b305-aaa9-4128-bb1b-dc6faaff73cd"
      },
      "source": [
        "from keras import applications\r\n",
        "from keras.models import Model, Input\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras import regularizers\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def transferNet(input_shape):\r\n",
        "    \r\n",
        "    # download model\r\n",
        "    base_model = applications.vgg19.VGG19(weights=\"imagenet\", include_top=False, input_shape=input_shape)\r\n",
        "    # get the output tensor from a layer of the feature extractor\r\n",
        "    tmp_vgg_output = base_model.get_layer(\"block4_conv3\").output\r\n",
        "    tmp_vgg_output = Conv2D(512, (3, 3), activation='linear', padding='same',name='block4_conv4')(tmp_vgg_output)\r\n",
        "    \r\n",
        "    vgg = Model(inputs=base_model.input, outputs=tmp_vgg_output)\r\n",
        "    vgg.load_weights(os.path.expanduser(os.path.join(\"~\", \".keras\", \"models\",\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")), by_name=True)\r\n",
        "\r\n",
        "    return vgg\r\n",
        "\r\n",
        "\r\n",
        "input_shape =(256,256,3)\r\n",
        "# load the pre-trained model\r\n",
        "vgg = transferNet(input_shape)\r\n",
        "vgg.summary()\r\n",
        "!ls ~/.keras/models\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "=================================================================\n",
            "Total params: 10,585,152\n",
            "Trainable params: 10,585,152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCcHgsTRbthT"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srtyDDuObvfV"
      },
      "source": [
        "from keras import applications\r\n",
        "from keras import layers\r\n",
        "from keras.models import Model, Input\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import *\r\n",
        "from keras import regularizers\r\n",
        "from keras import optimizers\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tfa\r\n",
        "\r\n",
        "\r\n",
        "def resblock(x_init):\r\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, padding='same')(x_init)\r\n",
        "    #x = (ZeroPadding2D(padding=(1, 1)))(x)\r\n",
        "    \r\n",
        "    x = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(x)\r\n",
        "    x = tf.nn.relu(x)\r\n",
        "    x = (Conv2D(256, kernel_size=3, strides=1, padding='same'))(x)\r\n",
        "    #x = (ZeroPadding2D(padding=(1, 1)))(x)\r\n",
        "    x = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(x)    \r\n",
        "\r\n",
        "    return x + x_init\r\n",
        "\r\n",
        "def create_generator(input_shape):\r\n",
        "    #model = Sequential()\r\n",
        "    #k7n64s1\r\n",
        "    input_t = tf.keras.layers.Input(shape=input_shape)\r\n",
        "    \r\n",
        "    model = (Conv2D(input_shape=input_shape, filters=64, kernel_size=7, strides=1, padding='same'))(input_t)\r\n",
        "    #model = (ZeroPadding2D(padding=(3, 3)))(model)\r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "    \r\n",
        "    #### Down-Convolution\r\n",
        "    \r\n",
        "    #k3 n128 s2\r\n",
        "    model = (Conv2D(filters=128, kernel_size=3, strides=2, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    #k3 n128 s1\r\n",
        "    model = (Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "\r\n",
        "\r\n",
        "    #k3 n256 s2\r\n",
        "    model = (Conv2D(filters=256, kernel_size=3, strides=2, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "\r\n",
        "    #k3 n256 s1\r\n",
        "    model = (Conv2D(filters=256, kernel_size=3, strides=1, padding='same', name=\"test\"))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    #TODO\r\n",
        "    # residual blocks\r\n",
        "    for i in range(8):#number of res blocks\r\n",
        "        '''model = (Conv2D(256, kernel_size=3, strides=1, padding='valid',activation=\"relu\"))(model)\r\n",
        "        model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "        \r\n",
        "        model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "        model = tf.nn.relu(model)\r\n",
        "\r\n",
        "        model = (Conv2D(256, kernel_size=3, strides=1, padding='valid',activation=\"relu\"))(model)\r\n",
        "        model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "        model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)'''\r\n",
        "        model = resblock(model)\r\n",
        "\r\n",
        "        \r\n",
        "        \r\n",
        "    \r\n",
        "    # Up-convolution\r\n",
        "    model = (Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',output_padding=1))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = (Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "    #######################\r\n",
        "    model = (Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same',output_padding=1))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "    \r\n",
        "    model = (Conv2D(filters=64, kernel_size=3, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(1, 1)))(model)\r\n",
        "\r\n",
        "    model = tfa.layers.InstanceNormalization(axis=3, center=True, scale=True)(model)\r\n",
        "    model = tf.nn.relu(model)\r\n",
        "\r\n",
        "    ###\r\n",
        "    model = (Conv2D(filters=3, kernel_size=7, strides=1, padding='same'))(model)\r\n",
        "    #model = (ZeroPadding2D(padding=(3, 3)))(model)\r\n",
        "    model = tf.tanh(model)\r\n",
        "\r\n",
        "    #model.compile(loss=tf.keras.losses.BinaryCrossentropy)\r\n",
        "    model = Model(inputs=input_t, outputs=model, name=\"generator\")\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "G = create_generator(input_shape=(256,256,3))\r\n",
        "#G.build(input_shape=(256,256,3)) #todo\r\n",
        "#G.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA6DDNnrdhex"
      },
      "source": [
        "\r\n",
        "#### Generator training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5qzOVIAyPO"
      },
      "source": [
        "#TODO\r\n",
        "from glob import glob\r\n",
        "import os\r\n",
        "from tqdm import tqdm\r\n",
        "import gc\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def pretrain_step(vgg, input_images, generator, optimizer):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        generated_images = generator(input_images)\r\n",
        "\r\n",
        "        plt.imshow(generated_images[0])\r\n",
        "        plt.imshow(input_images[0])\r\n",
        "        mae = tf.keras.losses.MeanAbsoluteError()\r\n",
        "        c_loss = mae(vgg(input_images), vgg(generated_images))\r\n",
        "\r\n",
        "        gradients = tape.gradient(c_loss, generator.trainable_variables)\r\n",
        "        optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\r\n",
        "        content_loss_metric = tf.keras.metrics.Mean(\"content_loss\", dtype=tf.float32)\r\n",
        "        content_loss_metric(c_loss)\r\n",
        "\r\n",
        "def pretrain_generator(dataset_name,batch_size):\r\n",
        "    summary_writer = tf.summary.create_file_writer(os.path.join('/content/drive/My Drive/NN', \"pretrain\"))\r\n",
        "    print(f\"Starting to pretrain generator with 10 epochs...\")\r\n",
        "    print(f\"Building `{dataset_name}` dataset\")\r\n",
        "    dataset, steps_per_epoch = get_dataset(dataset_name=dataset_name, batch_size=batch_size)\r\n",
        "    \r\n",
        "    generator = G\r\n",
        "    #generator(tf.keras.Input(shape=(None,256,256, 3)))\r\n",
        "    #generator.summary()\r\n",
        "\r\n",
        "    print(\"Setting up optimizer to update generator's parameters...\")\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0008, beta_1=0.5)\r\n",
        "\r\n",
        "    trained_epochs = 0\r\n",
        "    epochs = 10\r\n",
        "\r\n",
        "    print(\"Proceeding pretraining without sample images...\")\r\n",
        "\r\n",
        "    print(\"Starting pre-training loop, setting up summary writer to record progress on TensorBoard...\")\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        epoch_idx = trained_epochs + epoch + 1\r\n",
        "\r\n",
        "        for step in tqdm(range(1, steps_per_epoch + 1), desc=f\"Pretrain Epoch {epoch + 1}/{epochs}\"):\r\n",
        "            image_batch = dataset.next()\r\n",
        "            pretrain_step(vgg, image_batch, generator, optimizer)\r\n",
        "\r\n",
        "            if step % 100 == 0: #100 = pretrain_reporting_steps\r\n",
        "                global_step = (epoch_idx - 1) * steps_per_epoch + step\r\n",
        "                with summary_writer.as_default():\r\n",
        "                    tf.summary.scalar('content_loss', tf.keras.metrics.Mean(\"content_loss\", dtype=tf.float32).result(), step=global_step)\r\n",
        "\r\n",
        "                tf.keras.metrics.Mean(\"content_loss\", dtype=tf.float32).reset_states()\r\n",
        "        gc.collect()\r\n",
        "    return generator\r\n",
        "        \r\n",
        "gen_pretrained = pretrain_generator(\"photos_rszd/photos_resized\", 16)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfkOv_udyhlf"
      },
      "source": [
        "#### Show photos results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhQQAkSpw8dZ"
      },
      "source": [
        "'''y_true = [[0., 1.], [0., 0.]]\r\n",
        "y_pred = [[1., 1.], [1., 0.]]\r\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\r\n",
        "print(mae(y_true, y_pred).numpy())'''\r\n",
        "\r\n",
        "#savemodel(gen_pretrained,'initialization_phase_generator')\r\n",
        "dataset, steps_per_epoch = get_dataset(dataset_name=\"photos_rszd/photos_resized\", batch_size=16)\r\n",
        "input_images = dataset.next()\r\n",
        "plt.imshow(input_images[0])\r\n",
        "\r\n",
        "#gen_pretrained.predict(input_images[0])\r\n",
        "#%load_ext tensorboard\r\n",
        "#%tensorboard --logdir \"/content/drive/My Drive/NN/pretrain\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUPngw40dkbA"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StFKZT3Xdj6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6709c3-214b-4a1b-d5c0-45c62f1afdcd"
      },
      "source": [
        "from keras.layers import *\r\n",
        "def create_discriminator(input_shape):\r\n",
        "    model = Sequential()\r\n",
        "    #k7n64s1\r\n",
        "    model.add(Conv2D(input_shape=input_shape, filters=32, kernel_size=3, strides=1, padding='same',activation=LeakyReLU()))\r\n",
        "    \r\n",
        "    #k3n64s2\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=3, strides=2, padding='same',activation=LeakyReLU(alpha=0.2)))\r\n",
        "    \r\n",
        "    #k3n128s1\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(tfa.layers.InstanceNormalization(axis=3, center=True, scale=True))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    \r\n",
        "    #k3n128s2\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=2, padding='same',activation=LeakyReLU(alpha=0.2)))\r\n",
        "    #k3n256s1\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(tfa.layers.InstanceNormalization(axis=3, center=True, scale=True))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    #k3n256s1\r\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same'))\r\n",
        "    model.add(tfa.layers.InstanceNormalization(axis=3, center=True, scale=True))\r\n",
        "    model.add(LeakyReLU(alpha=0.2))\r\n",
        "    #k3n1s1\r\n",
        "    model.add(Conv2D(filters=1, kernel_size=3, strides=1, padding='same'))\r\n",
        "   \r\n",
        "    \r\n",
        "    #model.compile(loss=tf.keras.losses.BinaryCrossentropy)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "D = create_discriminator(input_shape=(256,256,3))\r\n",
        "D.summary()  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "instance_normalization (Inst (None, 128, 128, 128)     256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "instance_normalization_1 (In (None, 64, 64, 256)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "instance_normalization_2 (In (None, 64, 64, 256)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 64, 64, 1)         2305      \n",
            "=================================================================\n",
            "Total params: 1,129,665\n",
            "Trainable params: 1,129,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwtFZGzY3ijx"
      },
      "source": [
        "## Adversarial model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn5dJVoCwDZj"
      },
      "source": [
        "#### Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANRjg4TiuXKA"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "\r\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\r\n",
        "\r\n",
        "\r\n",
        "def discriminator_loss (real, fake, real_blur):\r\n",
        "    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(real), logits=real))\r\n",
        "    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(fake), logits=fake))\r\n",
        "    real_blur_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(real_blur), logits=real_blur))\r\n",
        "    \r\n",
        "    return real_loss+fake_loss+real_blur_loss\r\n",
        "\r\n",
        "def generator_loss(fake, vgg_loss):\r\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(fake), logits=fake)) + vgg_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnvicjC5wMzi"
      },
      "source": [
        "#### Get datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L35BLKrqwQAW",
        "outputId": "3db8e8aa-5d15-4c37-83c3-89afd5900bee"
      },
      "source": [
        "cartoon_set,steps_per_epoch = get_dataset(\"paprika_resized\",8)\r\n",
        "cartoon_smoothed_set, steps_per_epoch = get_dataset(\"paprika_resized_smoothed\",8)\r\n",
        "normal_photos_set,steps_per_epoch = get_dataset(\"photos_rszd/photos_resized\",8)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3591  images in paprika_resized folder.\n",
            "Found 3592  images in paprika_resized_smoothed folder.\n",
            "Found 3747  images in photos_rszd/photos_resized folder.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4y0r_NF-Uw1"
      },
      "source": [
        "### training GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frlQ1ENy6Ufu",
        "outputId": "284b3b4a-3070-4214-e235-70229f90393e"
      },
      "source": [
        "from IPython import display\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "def generate_and_save_images(model, epoch, test_input):\r\n",
        "    # Notice `training` is set to False.\r\n",
        "    # This is so all layers run in inference mode (batchnorm).\r\n",
        "    predictions = model(test_input)\r\n",
        "\r\n",
        "    fig = plt.figure(figsize=(4,4))\r\n",
        "\r\n",
        "    for i in range(predictions.shape[0]):\r\n",
        "        plt.subplot(4, 4, i+1)\r\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\r\n",
        "        plt.axis('off')\r\n",
        "\r\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "@tf.function\r\n",
        "def train_step(cartoon_set_batch, cartoon_smoothed_batch, normal_photos_batch):\r\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n",
        "        generated_images = gen_pretrained(normal_photos_batch)\r\n",
        "\r\n",
        "        real_output = D(cartoon_set_batch)\r\n",
        "        fake_output = D(generated_images)\r\n",
        "        real_smooth_output = D(cartoon_smoothed_batch)\r\n",
        "        \r\n",
        "        vgg_loss = mae(vgg(normal_photos_batch), vgg(cartoon_set_batch))\r\n",
        "        gen_loss = generator_loss(fake_output, vgg_loss)\r\n",
        "        disc_loss = discriminator_loss(real_output, fake_output, real_smooth_output)\r\n",
        "\r\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, gen_pretrained.trainable_variables)\r\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, D.trainable_variables)\r\n",
        "\r\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, gen_pretrained.trainable_variables))\r\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, D.trainable_variables))\r\n",
        "\r\n",
        "\r\n",
        "def train(dataset_1, dataset_2, dataset_3, epochs):\r\n",
        "    for epoch in range(epochs):\r\n",
        "        start = time.time()\r\n",
        "\r\n",
        "        for step in tqdm(\r\n",
        "                    range(1, steps_per_epoch + 1),\r\n",
        "                    desc=f'Train {epoch + 1}/{epochs}',\r\n",
        "                    total=steps_per_epoch):\r\n",
        "            cart_batch = dataset_1.next()\r\n",
        "            cart_smooth_batch = dataset_2.next()\r\n",
        "            norm_photos_batch = dataset_3.next()\r\n",
        "            train_step(cart_batch, cart_smooth_batch, norm_photos_batch)\r\n",
        "\r\n",
        "        # Produce images for the GIF as we go\r\n",
        "        #display.clear_output(wait=True)\r\n",
        "        #generate_and_save_images(gen_pretrained,epoch + 1)\r\n",
        "        '''# Save the model every 15 epochs\r\n",
        "        if (epoch + 1) % 15 == 0:\r\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)'''\r\n",
        "\r\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\r\n",
        "\r\n",
        "    # Generate after the final epoch\r\n",
        "    display.clear_output(wait=True)\r\n",
        "    #generate_and_save_images(gen_pretrained,epochs)\r\n",
        "\r\n",
        "train(cartoon_set, cartoon_smoothed_set, normal_photos_set, 5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 1200.456134557724 sec\n",
            "Time for epoch 2 is 526.7850053310394 sec\n",
            "Time for epoch 3 is 526.9260878562927 sec\n",
            "Time for epoch 4 is 526.417640209198 sec\n",
            "Time for epoch 5 is 527.0203611850739 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bhx1RgENNES"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHNsMV7PjXPq"
      },
      "source": [
        "def create_GAN():\r\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\r\n",
        "\r\n",
        "    discriminator_model = Sequential()\r\n",
        "    discriminator_model.add(D)\r\n",
        "    discriminator_model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\r\n",
        "    adv_model = Sequential()\r\n",
        "    adv_model.add(G)\r\n",
        "    adv_model.add(D)\r\n",
        "    adv_model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    return adv_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLtWRfFSNBmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a438ec-add9-44c0-e636-c87d481e3cfa"
      },
      "source": [
        "adv_model = create_GAN()\r\n",
        "adv_model.fit(\r\n",
        "        train_gen,\r\n",
        "        steps_per_epoch=2000,\r\n",
        "        epochs=50,\r\n",
        "        validation_data=validation_generator,\r\n",
        "        validation_steps=800,\r\n",
        "        verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}